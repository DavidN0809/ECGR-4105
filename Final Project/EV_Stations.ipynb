{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae756d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8069f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations = pd.DataFrame(pd.read_csv('EV_stations.csv'))\n",
    "EV_Vehicles = pd.DataFrame(pd.read_csv('predicted_vehicles.csv'))\n",
    "\n",
    "# Filter the 'Latitude' column of the dataframe to only include values greater than 30\n",
    "EV_Stations = EV_Stations.loc[EV_Stations['Latitude'] > 30]\n",
    "\n",
    "# View the resulting dataframe\n",
    "EV_Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23526ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations = EV_Stations[EV_Stations['State']=='WA']\n",
    "EV_Stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Vehicles = EV_Vehicles.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ZIP', 'Latitude', 'Longitude', 'Access Code','Open Date',\"ID\"]\n",
    "EV_Stations = EV_Stations[features]\n",
    "EV_Stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations.drop_duplicates(subset = \"ID\",keep = False, inplace= True) ##dropping duplicate vins\n",
    "EV_Stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba9a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of \"public\" with the value 1 in the \"Access Codes\" column\n",
    "EV_Stations['Access Code'] = EV_Stations['Access Code'].replace(\"public\", 1)\n",
    "EV_Stations['Access Code'] = EV_Stations['Access Code'].replace(\"private\", 0)\n",
    "EV_Stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=EV_Stations['Open Date'].values\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i] = int(y[i].split(\"/\")[-1])\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    EV_Stations.assign(Year = y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findingyears(year):\n",
    "    x=np.where(EV_Stations == year)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#findingyears(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e702034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr = [8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "arr1 = []\n",
    "\n",
    "for i in range(len(arr)):\n",
    "    x = findingyears(arr[i])\n",
    "    x = np.array(x)\n",
    "    arr1.append(x.size/2)\n",
    "#EV_Title_Year.insert(loc = 2, column = \"Number of EV\", value = arr1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e200eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(arr, arr1))\n",
    "df = pd.DataFrame(zipped, columns=['Year', 'Total_Installed'])\n",
    "df.head()\n",
    "total_installed=arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7498d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize = (10, 7))\n",
    "sns.barplot(x=\"Year\", y=\"Total_Installed\", data=df)\n",
    "plt.title('Year vs Total EV Stations')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Installed')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Bar Year vs Total EV Stations.jpg', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df[\"Year\"].values)\n",
    "y=np.array(df[\"Total_Installed\"].values)\n",
    "\n",
    "X=X.reshape(-1,1)\n",
    "y=y.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "x = [23,24,25,26,27,28,29,30,31,32,33]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler().fit(X_test)\n",
    "X_norm = min_max_scaler.transform(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "xtrain = sc_x.fit_transform(X_train) \n",
    "xtest = sc_x.transform(X_test)\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "classifier = linear_model.LinearRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "classifier.predict(X_train)\n",
    "\n",
    "x=X_train\n",
    "y=y_train\n",
    "n = np.size(x)\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "fig=plt.figure(figsize = (10, 7))\n",
    "plt.title('Year vs Total EV Stations Installed')\n",
    "sns.scatterplot(x=\"Year\", y=\"Total_Installed\", data=df)\n",
    "plt.plot(x,y_pred, color = 'green')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Installed')\n",
    "\n",
    "fig.savefig('Year Total EV Stations Predictions.jpg', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0029d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X_train\n",
    "y=y_train\n",
    "n = np.size(x)\n",
    "\n",
    "# Fit the data(train the model)\n",
    "classifier.fit(x, y)\n",
    "  \n",
    "# Predict\n",
    "y_predicted = classifier.predict(x)\n",
    "  \n",
    "# model evaluation\n",
    "mse=mean_squared_error(y,y_predicted)\n",
    "  \n",
    "rmse = np.sqrt(mean_squared_error(y, y_predicted))\n",
    "r2 = r2_score(y, y_predicted)\n",
    "  \n",
    "# printing values\n",
    "print('Slope:' ,classifier.coef_)\n",
    "print('Intercept:', classifier.intercept_)\n",
    "print('MSE:',mse)\n",
    "print('Root mean squared error: ', rmse)\n",
    "print('R2 score: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f09712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# You haven't provided the values of X_train and y_train, so I'm going to\n",
    "# use the years list as the x values and an array of zeros as the y values\n",
    "# for this example.\n",
    "\n",
    "x = [23,24,25,26,27,28,29,30,31,32,33]\n",
    "y = np.zeros(len(x))\n",
    "\n",
    "# You also haven't provided the classifier object, so I'm going to use a\n",
    "# dummy object for this example.\n",
    "\n",
    "# Now we can use the x and y values to plot the data\n",
    "\n",
    "# Reshape the x array to be a 2D array of size (n, 1) where n is the\n",
    "# number of elements in the array\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "\n",
    "# Use the classifier object to predict the y values for the x values\n",
    "y_pred = classifier.predict(x)\n",
    "\n",
    "# Create a figure object with a specified size\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Add a title to the plot\n",
    "plt.title('Year vs Total EV Stations Installed')\n",
    "\n",
    "# Plot the x and y values as a scatterplot\n",
    "sns.scatterplot(x=\"Year\", y=\"Total_Installed\", data=df)\n",
    "\n",
    "# Plot the predicted y values against the x values as a scatter plot\n",
    "plt.scatter(x, y_pred, color='green')\n",
    "# Label the x and y axes\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Added')\n",
    "\n",
    "fig.savefig('Year Total EV Installed 2033.jpg', bbox_inches='tight', dpi=150)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(1,-1)\n",
    "print(y_pred.shape)\n",
    "x=x.reshape(1,-1)\n",
    "print(x.shape)\n",
    "print(y_pred)\n",
    "df_x = pd.DataFrame({'Year': x, 'Total_nstalled': y_pred} )\n",
    "\n",
    "df = df.append(df_x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14685142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that converts the year to the format \"2008\", \"2009\", etc.\n",
    "def convert_year(year):\n",
    "    return f\"20{year}\"\n",
    "\n",
    "# apply the convert_year function to the year column of the dataframe\n",
    "df[\"Year\"] = df[\"Year\"].apply(convert_year)\n",
    "\n",
    "# use the replace method to replace \"208\" with \"2008\" and \"209\" with \"2009\"\n",
    "df[\"Year\"].replace({\"208\": \"2008\", \"209\": \"2009\"}, inplace=True)\n",
    "\n",
    "# display the modified dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567555cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predicted_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0176b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data = pd.merge(EV_Vehicles, df, on=\"Year\")\n",
    "#combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=np.array(combined_data[\"Year\"].values)\n",
    "#y=np.array(combined_data[ \"Total_Sold\"].values)\n",
    "\n",
    "#X=X.reshape(-1,1)\n",
    "#y=y.reshape(-1,1)\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "\n",
    "\n",
    "#min_max_scaler = MinMaxScaler().fit(X_test)\n",
    "#X_norm = min_max_scaler.transform(X)\n",
    "\n",
    "#sc_x = StandardScaler()\n",
    "#xtrain = sc_x.fit_transform(X_train) \n",
    "#xtest = sc_x.transform(X_test)\n",
    "#print (xtrain[0:10, :])\n",
    "\n",
    "\n",
    "#classifier = linear_model.LinearRegression()\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "#classifier.predict(X_train)\n",
    "\n",
    "#x=X_train\n",
    "#y=y_train\n",
    "#n = np.size(x)\n",
    "\n",
    "#y_pred = classifier.predict(X_train)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Variance score: {}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df[\"Year\"].values)\n",
    "y=np.array(df[\"Total_Installed\"].values)\n",
    "\n",
    "X=X.reshape(-1,1)\n",
    "y=y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e15e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "# Initialize the TPOT regressor.\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the regressor on the training data.\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set.\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f602b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TPOT regressor to make predictions on the new data.\n",
    "predictions = tpot.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb51d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = total_installed[-1]\n",
    "\n",
    "new_stations = np.subtract(y_pred, last)\n",
    "\n",
    "print(new_stations) # number of new stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc976c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'A' column of the dataframe to only include values less than 40\n",
    "EV_Stations = EV_Stations.loc[EV_Stations['Latitude'] > 30]\n",
    "\n",
    "# View the resulting dataframe\n",
    "EV_Stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotlonglat(data,filename):\n",
    "    import folium\n",
    "    import pandas as pd\n",
    "    from folium.plugins import HeatMap\n",
    "\n",
    "    #create a map\n",
    "    this_map = folium.Map(prefer_canvas=True)\n",
    "\n",
    "    def plotDot(point):\n",
    "        '''input: series that contains a numeric named latitude and a numeric named longitude\n",
    "        this function creates a CircleMarker and adds it to your this_map'''\n",
    "        folium.CircleMarker(location=[point.Latitude, point.Longitude],\n",
    "                            radius=2,\n",
    "                            weight=5).add_to(this_map)\n",
    "\n",
    "    #use df.apply(,axis=1) to \"iterate\" through every row in your dataframe\n",
    "    data.apply(plotDot, axis = 1)\n",
    "\n",
    "    #Set the zoom to the maximum possible\n",
    "    this_map.fit_bounds(this_map.get_bounds())\n",
    "    \n",
    "    #Save the map to an HTML file\n",
    "    this_map.save(filename)\n",
    "\n",
    "    return this_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2902a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotlonglat(EV_Stations,\"EV_Stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9316e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import mean, sqrt, square, arange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#split the data\n",
    "X = EV_Stations[['Open Date']]\n",
    "#X = X.values.reshape((len(X),3))\n",
    "y = EV_Stations[['Latitude', 'Longitude']]\n",
    "#y = y.values.reshape((len(y),1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Create the model and predict\n",
    "nn = 2\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "weights = 'distance'\n",
    "knn = neighbors.KNeighborsRegressor(nn, weights=weights)\n",
    "X_new=X_test\n",
    "y_pred = knn.fit(X_test, y_test).predict(X_new)\n",
    "\n",
    "err = y_pred - y_test\n",
    "rms = sqrt(mean(square(err)))\n",
    "\n",
    "print (rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred, columns=['Latitude', 'Longitude'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21cc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlonglat(df,\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae16640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "# Initialize the TPOT regressor\n",
    "X=np.array(EV_Stations[\"Open Date\"].values)\n",
    "y=np.array(EV_Stations[\"Longitude\"].values)\n",
    "\n",
    "X=X.reshape(-1,1)\n",
    "y=y.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(np.int64)\n",
    "X_test = X_test.astype(np.int64)\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the regressor on the training data.\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set.\n",
    "print(tpot.score(X_train, y_train))\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TPOT regressor to make predictions on the new data.\n",
    "predictions_long_tpot = tpot.predict(X_train)\n",
    "predictions_long_tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "# Initialize the TPOT regressor\n",
    "X=np.array(EV_Stations[\"Open Date\"].values)\n",
    "y=np.array(EV_Stations[\"Latitude\"].values)\n",
    "\n",
    "X=X.reshape(-1,1)\n",
    "y=y.reshape(-1,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(np.int64)\n",
    "X_test = X_test.astype(np.int64)\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the regressor on the training data.\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set.\n",
    "print(tpot.score(X_train, y_train))\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab88610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TPOT regressor to make predictions on the new data.\n",
    "predictions_lat_tpot = tpot.predict(X_train)\n",
    "predictions_lat_tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ed474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the arrays into a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# flatten the array1 variable\n",
    "predictions_long_tpot = predictions_long_tpot.flatten()\n",
    "predictions_lat_tpot = predictions_lat_tpot.flatten()\n",
    "\n",
    "df_tpot = pd.DataFrame(data={'Latitude': predictions_lat_tpot, 'Longitude': predictions_long_tpot})\n",
    "# print the dataframe\n",
    "df_tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlonglat(df_tpot,\"predicted_tpot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bdf7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data\n",
    "X = EV_Stations['Open Date'].values\n",
    "#X = X.values.reshape((len(X),3))\n",
    "y = EV_Stations['Latitude'].values\n",
    "#y = y.values.reshape((len(y),1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.int64)\n",
    "X_test = X_test.astype(np.int64)\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    # Add a dense layer with 11 neurons and an input shape of (1,), with l2 regularization\n",
    "    keras.layers.Dense(1284, input_shape=(1,), kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    # Add a sigmoid activation function\n",
    "    keras.layers.Activation('relu'),\n",
    "    # Add a dense layer with 1 neuron and a sigmoid activation function, with l2 regularization\n",
    "    keras.layers.Dense(1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Fit the model on the data\n",
    "model.fit(X_train, y_train, epochs=70)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions_lat = model.predict(X_train)\n",
    "print(predictions_lat)\n",
    "# Evaluate the model on the testing data\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa104c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data\n",
    "X = EV_Stations['Open Date'].values\n",
    "X=abs(X)\n",
    "#X = X.values.reshape((len(X),3))\n",
    "y = EV_Stations['Longitude'].values\n",
    "y=abs(y)\n",
    "#y = y.values.reshape((len(y),1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.int64)\n",
    "X_test = X_test.astype(np.int64)\n",
    "\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    # Add a dense layer with 11 neurons and an input shape of (1,), with l2 regularization\n",
    "    keras.layers.Dense(1284, input_shape=(1,), kernel_regularizer=keras.regularizers.l2(0.0001)),\n",
    "    # Add a sigmoid activation function\n",
    "    keras.layers.Activation('selu'),\n",
    "    # Add a dense layer with 1 neuron and a sigmoid activation function, with l2 regularization\n",
    "    keras.layers.Dense(1, activation='selu', kernel_regularizer=keras.regularizers.l2(0.0001))\n",
    "])\n",
    "\n",
    "#softplus, selu, relu, elu\n",
    "#selu, elu\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Fit the model on the data\n",
    "model.fit(X_train, y_train, epochs=70)\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "predictions_long = model.predict(X_train)\n",
    "print(predictions_long)\n",
    "# Evaluate the model on the testing data\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Apply minus operator to each element of array\n",
    "predictions_long = -predictions_long\n",
    "print(predictions_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lat=predictions_lat.reshape(-1,1)\n",
    "print(predictions_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05082310",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(predictions_long,predictions_lat))\n",
    "df_nn = pd.DataFrame(zipped, columns=['Longitude','Latitude'])\n",
    "df_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01555fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlonglat(df_nn,\"Predicted NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9b067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
