{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5befd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea81c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations = pd.DataFrame(pd.read_csv('predicted_stations.csv'))\n",
    "EV_Grid = pd.DataFrame(pd.read_csv('predicted_grid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c475c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Stations = EV_Stations.drop(columns='Unnamed: 0')\n",
    "EV_Stations = EV_Stations.loc[(EV_Stations['Year'] >= 2010) & (EV_Stations['Year'] <= 2022)]\n",
    "EV_Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213701ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Vehicles = pd.DataFrame(pd.read_csv('predicted_vehicles.csv'))\n",
    "EV_Vehicles = EV_Vehicles.drop(columns='Unnamed: 0')\n",
    "EV_Vehicles = EV_Vehicles.loc[(EV_Vehicles['Year'] >= 2010) & (EV_Vehicles['Year'] <= 2022)]\n",
    "EV_Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Grid = EV_Grid.drop(columns='Unnamed: 0')\n",
    "EV_Grid = EV_Grid.loc[(EV_Grid['Year'] >= 2010) & (EV_Grid['Year'] <= 2022)]\n",
    "EV_Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# create a copy of the ev_grid array\n",
    "ev_grid_scaled = EV_Grid.copy()\n",
    "\n",
    "# select the predicted column\n",
    "predicted_column = ev_grid_scaled['Predicted_MWH']\n",
    "\n",
    "# scale the ev_grid value for all rows except the last row\n",
    "predicted_column[:-1] = predicted_column[:-1] / math.exp(8)\n",
    "\n",
    "# multiply the last row by e^7\n",
    "#predicted_column[-1] = predicted_column[-1] * math.exp(7)\n",
    "last_row = ev_grid_scaled.tail(1)\n",
    "last_row = last_row / math.exp(7)\n",
    "# change the last row of the predicted column\n",
    "ev_grid_scaled.iloc[-1, ev_grid_scaled.columns.get_loc('Predicted_MWH')] = last_row\n",
    "# update the predicted column in the ev_grid_scaled array\n",
    "ev_grid_scaled['Predicted_MWH'] = predicted_column\n",
    "\n",
    "\n",
    "ev_grid_scaled['Predicted_MWH'] = ev_grid_scaled['Predicted_MWH'].astype(int)\n",
    "EV_Grid=ev_grid_scaled\n",
    "\n",
    "EV_Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EV_Vehicles.shape)\n",
    "print(EV_Stations.shape)\n",
    "print(EV_Grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f76d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into X (features) and y (target)\n",
    "df = pd.merge(EV_Stations, EV_Grid, on='Year')\n",
    "X = np.array(df[['Total_Installed', 'Predicted_MWH']])\n",
    "y = np.array(EV_Stations['Year'])\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3cea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "num_inputs = 2\n",
    "num_outputs = 1\n",
    "\n",
    "hidden_size = [32, 64, 128, 256]\n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Linear(num_inputs, hidden_size[0]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[1], hidden_size[2]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[2], hidden_size[3]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[3],num_outputs),\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create an instance of the MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "y=y.reshape(-1,1)\n",
    "\n",
    "# fit the scaler to the data\n",
    "scaler_x.fit(X)\n",
    "scaler_y.fit(y)\n",
    "\n",
    "# transform the data\n",
    "X = scaler_x.transform(X)\n",
    "y = scaler_y.transform(y)\n",
    "\n",
    "# normalize and scale the data\n",
    "X_mean = X.mean()\n",
    "X_std = X.std()\n",
    "y_mean = y.mean()\n",
    "y_std = y.std()\n",
    "\n",
    "X = (X - X_mean) / X_std\n",
    "y = (y - y_mean) / y_std\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# convert the data to tensors\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "print(model)\n",
    "# train the model\n",
    "for epoch in range(1000):\n",
    "    # forward pass\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print training and testing accuracy\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/1000: Training loss = {loss.item():.4f}')\n",
    "        with torch.no_grad():\n",
    "            y_pred_test = model(X_test)\n",
    "            test_loss = criterion(y_pred_test, y_test)\n",
    "            print(f'Epoch {epoch+1}/1000: Testing loss = {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f644f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data point\n",
    "X_new = pd.DataFrame({'Year': [2023], 'EV_stations': [264.0]})\n",
    "\n",
    "# convert the data to a tensor\n",
    "X_new = torch.from_numpy(X_new.values).float()\n",
    "\n",
    "# normalize and scale the data\n",
    "#X_new = (X_new - X_mean) / X_std\n",
    "\n",
    "# make predictions using the model\n",
    "y_pred = model(X_new)\n",
    "\n",
    "# de-normalize the prediction\n",
    "y_pred = y_pred * y_std + y_mean\n",
    "\n",
    "print(f'Predicted grid power for 2033 with 1574 EV stations: {y_pred.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea945d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data point\n",
    "X_new = pd.DataFrame({'Year': [2023], 'EV_stations': [238.11287478]})\n",
    "\n",
    "year = [2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033]\n",
    "stations = [238.11287478,\n",
    " 256.39153439, 274.670194,   292.94885362, 311.22751323, 329.50617284, 347.78483245, 366.06349206, 384.34215168, 402.62081129,\n",
    "  420.8994709]\n",
    "\n",
    "\n",
    "# convert the data to a tensor\n",
    "X_new = torch.from_numpy(X_new.values).float()\n",
    "\n",
    "# normalize and scale the data\n",
    "#X_new = (X_new - X_mean) / X_std\n",
    "\n",
    "# make predictions using the model\n",
    "y_pred = model(X_new)\n",
    "\n",
    "# de-normalize the prediction\n",
    "y_pred = y_pred * y_std + y_mean\n",
    "\n",
    "import math\n",
    "\n",
    "# multiply the number by e^4\n",
    "result = y_pred.item() * math.exp(5)\n",
    "result\n",
    "print(f'Predicted grid power for 2023 with 238 EV stations: {result:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Define the year and number of stations lists\n",
    "year = [2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033]\n",
    "stations = [238.11287478,\n",
    " 256.39153439, 274.670194,   292.94885362, 311.22751323, 329.50617284, 347.78483245, 366.06349206, 384.34215168, 402.62081129,\n",
    "  420.8994709]\n",
    "\n",
    "# Create empty lists to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the year and number of stations lists\n",
    "for i in range(len(year)):\n",
    "    # Create a new data point\n",
    "    X_new = pd.DataFrame({'Year': [year[i]], 'EV_stations': [stations[i]]})\n",
    "\n",
    "    # Convert the data to a tensor\n",
    "    X_new = torch.from_numpy(X_new.values).float()\n",
    "\n",
    "    # Normalize and scale the data\n",
    "    #X_new = (X_new - X_mean) / X_std\n",
    "\n",
    "    # Make predictions using the model\n",
    "    y_pred = model(X_new)\n",
    "\n",
    "    # De-normalize the prediction\n",
    "    y_pred = y_pred * y_std + y_mean\n",
    "\n",
    "    # Multiply the prediction by e^4\n",
    "    result = y_pred * math.exp(5)\n",
    "    \n",
    "    # Add the prediction to the list\n",
    "    predictions.append(result.item())\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(year,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=X_train\n",
    "#y=y_train\n",
    "df = pd.DataFrame(pd.read_csv('annual_generation_WA.csv'))\n",
    "\n",
    "x= np.arange(32) + 1990\n",
    "\n",
    "y = df.Total.values\n",
    "\n",
    "\n",
    "n = np.size(x)\n",
    "predictions=predictions/math.exp(8)\n",
    "fig=plt.figure(figsize = (15,6))\n",
    "plt.title('Grid Capacity by Year')\n",
    "plt.plot(x,y)\n",
    "plt.plot(year,predictions)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Capacity in MWH')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
